{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bag of words",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQPeQy6w0x0wS8pmUQhcpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishgeorge1811/naturallanguage/blob/master/bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEFXs4ShEyhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaBK8eZCE3CB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. \n",
        "               Thank you to all of you in this room. I have to congratulate \n",
        "               the other incredible nominees this year. The Revenant was \n",
        "               the product of the tireless efforts of an unbelievable cast\n",
        "               and crew. First off, to my brother in this endeavor, Mr. Tom \n",
        "               Hardy. Tom, your talent on screen can only be surpassed by \n",
        "               your friendship off screen … thank you for creating a t\n",
        "               ranscendent cinematic experience. Thank you to everybody at \n",
        "               Fox and New Regency … my entire team. I have to thank \n",
        "               everyone from the very onset of my career … To my parents; \n",
        "               none of this would be possible without you. And to my \n",
        "               friends, I love you dearly; you know who you are. And lastly,\n",
        "               I just want to say this: Making The Revenant was about\n",
        "               man's relationship to the natural world. A world that we\n",
        "               collectively felt in 2015 as the hottest year in recorded\n",
        "               history. Our production needed to move to the southern\n",
        "               tip of this planet just to be able to find snow. Climate\n",
        "               change is real, it is happening right now. It is the most\n",
        "               urgent threat facing our entire species, and we need to work\n",
        "               collectively together and stop procrastinating. We need to\n",
        "               support leaders around the world who do not speak for the \n",
        "               big polluters, but who speak for all of humanity, for the\n",
        "               indigenous people of the world, for the billions and \n",
        "               billions of underprivileged people out there who would be\n",
        "               most affected by this. For our children’s children, and \n",
        "               for those people out there whose voices have been drowned\n",
        "               out by the politics of greed. I thank you all for this \n",
        "               amazing award tonight. Let us not take this planet for \n",
        "               granted. I do not take tonight for granted. Thank you so very much.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZkFy4XiMUtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#By Stemming"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS4eRbmgE3Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "output = []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a-z,A-Z]',\" \",sentences[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [ps.stem(word)for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = \" \".join(review)\n",
        "  output.append(review)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KRfKNEAE3Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "720e593b-5705-4c45-fb9f-40952bf38b9e"
      },
      "source": [
        "output"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thank much',\n",
              " 'thank academi',\n",
              " 'thank room',\n",
              " 'congratul incred nomine year',\n",
              " 'reven product tireless effort unbeliev cast crew',\n",
              " 'first off, brother endeavor, mr tom hardi',\n",
              " 'tom, talent screen surpass friendship screen thank creat ranscend cinemat experi',\n",
              " 'thank everybodi fox new regenc entir team',\n",
              " 'thank everyon onset career parent none would possibl without',\n",
              " 'friends, love dearli know',\n",
              " 'lastly, want say make reven man relationship natur world',\n",
              " 'world collect felt hottest year record histori',\n",
              " 'product need move southern tip planet abl find snow',\n",
              " 'climat chang real, happen right',\n",
              " 'urgent threat face entir species, need work collect togeth stop procrastin',\n",
              " 'need support leader around world speak big polluters, speak humanity, indigen peopl world, billion billion underprivileg peopl would affect',\n",
              " 'children children, peopl whose voic drown polit greed',\n",
              " 'thank amaz award tonight',\n",
              " 'let us take planet grant',\n",
              " 'take tonight grant',\n",
              " 'thank much']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGrrrQPyE3Nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bag of words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu6nOVJyE3R4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "d8b03476-5878-4712-c375-a68f663e3fa5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X=cv.fit_transform(output).toarray()\n",
        "print(X)\n",
        "X.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4N-C-eQE3Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################################################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MUtBzh-E3U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################################################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsbOs2LAE3QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#By lemmatizing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7VcZHRmE3Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet = WordNetLemmatizer()\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "output1 = []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  review = re.sub('[^a-z,A-Z]',\" \",sentences[i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  review = [wordnet.lemmatize(word)for word in review if not word in set(stopwords.words('english'))]\n",
        "  review = \" \".join(review)\n",
        "  output1.append(review)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIHsKGDWE3FE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "416ce837-1979-4fff-fbbf-33bb16974e4c"
      },
      "source": [
        "output1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['thank much',\n",
              " 'thank academy',\n",
              " 'thank room',\n",
              " 'congratulate incredible nominee year',\n",
              " 'revenant product tireless effort unbelievable cast crew',\n",
              " 'first off, brother endeavor, mr tom hardy',\n",
              " 'tom, talent screen surpassed friendship screen thank creating ranscendent cinematic experience',\n",
              " 'thank everybody fox new regency entire team',\n",
              " 'thank everyone onset career parent none would possible without',\n",
              " 'friends, love dearly know',\n",
              " 'lastly, want say making revenant man relationship natural world',\n",
              " 'world collectively felt hottest year recorded history',\n",
              " 'production needed move southern tip planet able find snow',\n",
              " 'climate change real, happening right',\n",
              " 'urgent threat facing entire species, need work collectively together stop procrastinating',\n",
              " 'need support leader around world speak big polluters, speak humanity, indigenous people world, billion billion underprivileged people would affected',\n",
              " 'child children, people whose voice drowned politics greed',\n",
              " 'thank amazing award tonight',\n",
              " 'let u take planet granted',\n",
              " 'take tonight granted',\n",
              " 'thank much']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYMXAg-tNN4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "6ab8468c-dac1-40c3-88e7-ca563449a481"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X1=cv.fit_transform(output1).toarray()\n",
        "print(X)\n",
        "X1.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 109)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmrCzhZDNkB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}